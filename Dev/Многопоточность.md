# Проблемы
- гонки (race condition)
- взаимные блокировки (deadlock). Диагностика: Dl-check, jstack
# Создание потока
- создать экземпляр класса Thread
- создать экземпляр класса Runnable и передать в экземпляр класса Thread

```scala
object Test extends App {  
  for (_ <- 1 to 10)  
    new Thread(new r).start()  
    // new Thread(() => println(s"Hello from ${Thread.currentThread().getName}")).start() запуск через лямбду
    // new t().start()  
  
  println(s"Hello from main")  
    
  class t extends Thread {  
    override def run(): Unit = {  
      println(s"Hello from ${this.getName}")  
    }  
  }  
  
  class r extends Runnable {  
    override def run(): Unit = {  
      println(s"Hello from ${Thread.currentThread().getName}")  
    }  
  }  
}
```
Запускается поток методом start, если перепутать его с методом run, то произойдет запуск из основного потока.

# Прерывание потока
thread.interrupt() прерывает поток
Если поток находится в ожидании (sleep, join, wait), то ожидание прерывается исключением InterruptedException.

```scala
val worker = new WorkT  
val sleeper = new SleepT  
  
println("Start")  
worker.start()  
sleeper.start()  
  
Thread.sleep(1000)  
  
println("Interrupting...")  
worker.interrupt()  
sleeper.interrupt()  
  
println("Joining...")  
worker.join()  
sleeper.join()  
  
println(s"Done")  
  
class WorkT extends Thread {  
  override def run(): Unit = {  
    var sum = 0  
    for (i <- 0 to 1_000_000_000) {  
      sum += 1  
      if (sum % 100 == 0 && isInterrupted) {  
        println(s"Loop interrupted i=$i")  
        return  
      }  
    }  
  }  
}  
  
class SleepT extends Thread {  
  override def run(): Unit = {  
    try {  
      Thread.sleep(10000)  
    } catch {  
      case _: InterruptedException => println("Sleep interrupted")  
    }  
  }  
}
```
# synchronized
```scala
synchronized(obj){} // монитор объект obj
synchronized void method(){} // монитор объект this
synchronized static void method(){} // монитор объект .class
```

ArrayList, HashSet, LinketHashSet, TreeSet, HashMap не потокобезопасные, то есть при доступе из нескольких потоков может произойти все что угодно

Завершение synchronized устанавливает hb для следующей синхронизации по тому же объекту

```scala
val acc = Account(20_000)  
println(s"Begin balance = ${acc.getBalance}")  
  
val withdrawT = new WithdrawT(acc)  
val depositT = new DepositT(acc)  
withdrawT.start()  
depositT.start()  
  
withdrawT.join()  
depositT.join()  
  
println(s"End balance = ${acc.getBalance}")  
  
case class Account(private var balance: Long) {  
  def getBalance: Long = balance  
  def deposit(amount: Long): Unit = synchronized {  
    balance += amount  
  }  
  
  def withdraw(amount: Long): Unit = synchronized {  
    if (balance < amount)  
      throw new IllegalArgumentException("not enough money")  
    balance -= amount  
  }  
}  
  
class WithdrawT(account: Account) extends Thread {  
  override def run(): Unit =  
    for (_ <- 0 until 20_000)  
      account.withdraw(1)  
}  
  
class DepositT(account: Account) extends Thread {  
  override def run(): Unit =  
    for (_ <- 0 until 20_000)  
      account.deposit(1)  
}
```

Методы wait (приостанавливает текущий поток и освобождает блокировку монитора) и notify можно вызывать только внутри synchronized блока. Бывает управление из метода wait возвращается даже если никто не вызывал notify, поэтому его обычно оборачивают в цикл который проверяет условие которое мы ждем

```scala
val acc = Account(0)  
  
println(s"Begin balance = ${acc.getBalance}")  
  
val depositT = new DepositT(acc)  
depositT.start()  
  
acc.waitAndWithdraw(20_000)  
  
println(s"End balance = ${acc.getBalance}")  
  
case class Account(private var balance: Long) {  
  def getBalance: Long = balance  
  def deposit(amount: Long): Unit = synchronized {  
    balance += amount  
    notifyAll()  
  }  
  
  def waitAndWithdraw(amount: Long): Unit = synchronized {  
    while (balance < amount)  
      wait()  
    balance -= amount  
  }  
}  
  
class DepositT(account: Account) extends Thread {  
  override def run(): Unit =  
    for (_ <- 0 until 20_000)  
      account.deposit(1)  
}
```
# Атомарность
- Чтение и запись в поле типа boolean, byte, short, char, int, float, int, Object (то есть всех типов, кроме long и double) атомарна
- Чтение и запись в поле типа long/double объявленное volatile атомарна 

# Правила happens before
Событие А из потока Т1 находится в hb с событием В в потоке Т2, если все что произошло до события А в Т1 видно после события В в Т2
- Инициализация объекта гарантирует hb то есть что мы прочитаем заново проинициализированный объект
- Запись volatile поля устанавливает hb с чтением из него
- Освобождение монитора устанавливает hb с захватом того же монитора
- Вызов thread.start() устанавливает hb с thread.run() то есть в run мы увидим все что произошло до thread.start()
- Завершение thread.run() устанавливает hb с thread.join() то есть после join мы увидим все что произошло в run
- Для 2х операций А и В в одном потоке А hb В, если А раньше В в тексте программы

# Volatile
- Массивы не могут быть volatile
```java
volatile int[] x;
x = new int[10]; // volatile write
x[0]=1; // volatile read, plain write
```

# JavaUtilConcurrent
## Атомарные типы
```scala
java.util.concurrent.atomic

AtomicBoolean  
AtomicInteger  
AtomicLong  
AtomicReference[V]

// operations
get: V
set(value: V)
compareAndSet(expect: V, update: V): Boolean
```

Обычная реализация
```scala
var counter = 0  
  
def nextInt = synchronized {  
  counter += 1  
  counter  
}  
  
var  threads = Array[Thread]()  
for (_ <- 0 until 10) {  
  val thread = new Thread(() => for (_ <- 0 until 1000) nextInt)  
  thread.start()  
  threads = thread +: threads  
}  
for (t <- threads) t.join()  
  
println(s"Counter value = $counter")
```

На атомиках
```scala
var counter = new AtomicInteger()  
  
def nextInt = counter.getAndIncrement()  
  
var  threads = Array[Thread]()  
for (_ <- 0 until 10) {  
  val thread = new Thread(() => for (_ <- 0 until 1000) nextInt)  
  thread.start()  
  threads = thread +: threads  
}  
for (t <- threads) t.join()  
  
println(s"Counter value = $counter")
```

## Semaphore
Ограничивает одновременный доступ к ресурсу числом N. Операция acquire захватывает семафор, а release освобождает. Если вторым параметром в семафор передать true то потоки по очереди будут подучать к нему доступ, иначе доступ почти всегда будут захватывать первые 2 потока
Пример: получение ограниченного количества коннектов к БД
```scala
val s = new Semaphore(10)  

s.acquire()  
try {  
  // up to 10 threads may execute this code concurrently  
} finally {  
  s.release()  
}
```

```scala
val s = new Semaphore(2, true)  
  
var threads = Array[Thread]()  
for (_ <- 0 until 10) {  
  val thread = new SemaphoreThread(s)  
  threads = thread +: threads  
  thread.start()  
}  
Thread.sleep(20_000)  
for (t <- threads) t.interrupt()  
  
println("End")  
  
class SemaphoreThread(s: Semaphore) extends Thread {  
  override def run(): Unit = {  
    try {  
      while (true) {  
        s.acquire()  
        try {  
          println(s"$getName acquired semaphore")  
          Thread.sleep(5_000)  
        } finally {  
          println(s"$getName releasing semaphore")  
          s.release()  
        }  
      }  
    } catch {  
      case _: InterruptedException => println(s"$getName interrupted")  
    }  
  }  
}
```

## CountDownLatch
Когда нужно чтобы несколько потоков дождались друг друга а потом стартовали одновременно. 
Например несколько потоков инициализируются с разной скоростью, но как они инициализировались всех запускаем на выполнение основной работы
Метод countDown уменьшает счетчик на 1, метод await ждет когда счетчик станет нулем

```scala
val c = new CountDownLatch(10)  
  
for (_ <- 0 until 10)  
  new CountDownThread(c).start()  
  
class CountDownThread(c: CountDownLatch) extends Thread {  
  override def run(): Unit = {  
    try {  
      Thread.sleep(new scala.util.Random().between(5_000, 10_000))  
      println(s"$getName finished init")  
      c.countDown()  
      c.await()  
      println(s"$getName entered main phase")  
    } catch {  
      case _: InterruptedException => println(s"$getName interrupted")  
    }  
  }  
}
```

## CyclicBarrier
Вариант CountDownLatch допускающий повторное ожидание. Если вторым параметром передать true то получим честную очередь

## ReentrantLock
Реализует взаимное исключение нескольких потоков. Один поток может захватывать лок много раз, но после этого его нужно разлочить нужное количество раз

```scala
val lock = new ReentrantLock()  

lock.lock()  
try {  
  // do smth  
} finally {  
  lock.unlock()  
}
```

## Condition
Аналог wait/notify -> await/signal. Привязан к Lock, Lock может иметь несколько condition
Пример Извлекаем элемент из очереди если она не пуста иначе ждем, добавляем в очередь элемент если она не полна, иначе ждем

```scala
val lock = new ReentrantLock()  
val cond = lock.newCondition()  
  
lock.lock()  
try {  
  while (!condSatisfied) {  
    cond.await()  
  }  
} finally {  
  lock.unlock()  
}  
  
// somewhere else  
lock.lock()  
try {  
  cond.signal()  
} finally {  
  lock.unlock()  
}
```

```scala
val acc = Account(0)  
  
println(s"Begin balance = ${acc.getBalance}")  
  
val depositT = new DepositT(acc)  
depositT.start()  
  
acc.waitAndWithdraw(20_000)  
  
println(s"End balance = ${acc.getBalance}")  
  
case class Account(private var balance: Long) {  
  val lock = new ReentrantLock()  
  val balanceInc = lock.newCondition()  
  
  def getBalance: Long = {  
    lock.lock()  
    try {  
      balance  
    } finally {  
      lock.unlock()  
    }  
  }  
  def deposit(amount: Long): Unit = {  
    lock.lock()  
    try {  
      balance += amount  
      balanceInc.signalAll()  
    } finally {  
      lock.unlock()  
    }  
  }  
  
  def waitAndWithdraw(amount: Long): Unit = {  
    lock.lock()  
    try {  
      while (balance < amount) {  
        balanceInc.await()  
      }  
      balance -= amount  
    } finally {  
      lock.unlock()  
    }  
  }  
}  
  
class DepositT(account: Account) extends Thread {  
  override def run(): Unit =  
    for (_ <- 0 until 21_000)  
      account.deposit(1)  
}
```

## ReentrantReadWriteLock
Поддерживает доступ с разделением на чтение и запись

```scala
val lock = new ReentrantReadWriteLock()  
  
lock.readLock().lock()  
try {  
  // readOnlyOps  
} finally {  
  lock.readLock().unlock()  
}  

// somewhere else  
lock.writeLock().lock()  
try {  
  // writeOnlyOps  
} finally {  
  lock.writeLock().unlock()  
}
```

## Многопоточные коллекции
- ConcurrentHashMap  
- ConcurrentSkipListMap // TreeMap  
- ConcurrentSkipListSet // TreeSet  
- CopyOnWriteArrayList // ArrayList 
- CopyOnWriteArraySet

- Collections.synchronizedCollection() - позволяет работать с обычной коллекцией в режиме многопоточного доступа
- ConcurrentLinkedQueue - очередь с доступом из нескольких потоков. Добавляем с одной стороны забираем с другой (ConcurrentLinkedDeque добавляет и удаляет с 2х сторон, но работает медленней). Нет нативной реализации ожидания. Операции: offer(e: E), poll, peek
- BlockingQueue - очередь с доступом из нескольких потоков с нативной реализацией ожидания. Операции: put(e: E), take. Реализации LinkedBlockingQueue  и ArrayBlockingQueue

## ExecutorService
Создает потоки, организует очередь задач, распределяет задачи по потокам. Операции: submit (отдать работу на выполнение), shutdown, shutdownNow
- Executors.newSingleThreadExecutor()
- Executors.newFixedThreadPool(10)
- Executors.newCachedThreadPool()

```scala
val exec = Executors.newFixedThreadPool(2)  
  
println("submit worker 1")  
val f1 = exec.submit(new Worker("w1"))  
  
println("submit worker 2")  
val f2 = exec.submit(new Worker("w2"))  

println(s"res worker 1 ${f1.get}")  
println(s"res worker 2 ${f2.get}")  

exec.shutdown()  
exec.awaitTermination(10L, TimeUnit.SECONDS)
  
class Worker(name: String) extends Callable[String]{  
  override def call(): String = {  
    println(s"$name started")  
    Thread.sleep(5_000)  
    println(s"$name finished")  
    name  
  }  
}
```

invokeAll - запускает пачку задач на выполнение и дожидается исполнения всех задач то есть он блокирующий
```scala
val exec = Executors.newFixedThreadPool(2)  
  
println("submit worker 1")  
val futures = exec.invokeAll(util.Arrays.asList(new Worker("w1"), new Worker("w2"))).asScala  
  
for (f <- futures)  
  println(s"res from worker ${f.get()}")  
  
exec.shutdown()  
exec.awaitTermination(10L, TimeUnit.SECONDS)  
  
class Worker(name: String) extends Callable[String]{  
  override def call(): String = {  
    println(s"$name started")  
    Thread.sleep(5_000)  
    println(s"$name finished")  
    name  
  }  
}
```

## ForkJoinPool
декомпозирует задачу на подзадачи и выполняет их параллельно. Пример: сортировка массива алгоритмом mergeSort

## Параллельные стримы
Запускается на обычном стриме дальнейшие операции в котором будут выполняться параллельно
```scala
util.Arrays.stream(Array(1, 2, 3))
.parallel()
.mapToLong(_ * 10L)
.sum()
```

## CompletableFuture
runAsync, supplyAsync - запускает выполнение
thenCombine - операции над 2 футурами
join - дожидается результата
